import os
import numpy as np
from PIL import Image
import torch
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import pytorch_lightning as pl
from transformers import SegformerForSemanticSegmentation, SegformerImageProcessor

# === Configurations ===
IMAGE_DIR = 'C:/Users/Public/segformer/dataset/train/images'
MASK_DIR = 'C:/Users/Public/segformer/dataset/train/masks'
TEST_IMAGE_DIR = 'C:/Users/Public/segformer/dataset/test/images'
TEST_MASK_DIR = 'C:/Users/Public/segformer/dataset/test/masks'
NUM_CLASSES = 2

# === Dataset ===
class SegmentationDataset(Dataset):
    def __init__(self, image_dir, mask_dir, feature_extractor, resize=(512, 512)):
        self.image_dir = image_dir
        self.mask_dir = mask_dir
        self.resize = resize
        self.feature_extractor = feature_extractor
        self.images = sorted(os.listdir(image_dir))
        self.masks = sorted(os.listdir(mask_dir))

    def __len__(self):
        return len(self.images)
    
    def __getitem__(self, idx):
        image = Image.open(os.path.join(self.image_dir, self.images[idx])).convert("RGB")
        mask = Image.open(os.path.join(self.mask_dir, self.masks[idx])).convert("L")
        image = image.resize(self.resize)
        mask = mask.resize(self.resize)
        
        encoding = self.feature_extractor(images=image, return_tensors="pt")
        pixel_values = encoding['pixel_values'].squeeze(0)
        
        mask = np.array(mask)
        mask = (mask > 127).astype(np.uint8)
        mask = np.clip(mask, 0, NUM_CLASSES - 1)
        mask = torch.tensor(mask, dtype=torch.long)
        
        encoding['labels'] = mask
        encoding['pixel_values'] = pixel_values
        return encoding

# === Loss Functions & Metrics ===
def tversky_loss(logits, labels, alpha=0.7, beta=0.3, smooth=1e-6):
    num_classes = logits.shape[1]
    labels_one_hot = F.one_hot(labels, num_classes).permute(0, 3, 1, 2).float()
    probs = torch.softmax(logits, dim=1)
    tversky_loss_value = 0.0
    for c in range(num_classes):
        prob_c = probs[:, c, :, :]
        true_c = labels_one_hot[:, c, :, :]
        TP = (prob_c * true_c).sum(dim=(1, 2))
        FP = (prob_c * (1 - true_c)).sum(dim=(1, 2))
        FN = ((1 - prob_c) * true_c).sum(dim=(1, 2))
        tversky_index = (TP + smooth) / (TP + alpha * FP + beta * FN + smooth)
        tversky_loss_value += (1 - tversky_index).mean()
    tversky_loss_value /= num_classes
    return tversky_loss_value

def combined_loss(logits, labels, weight_ce=1.0, weight_tv=1.0, smooth=1e-6, alpha=0.7, beta=0.3):
    ce_loss = torch.nn.CrossEntropyLoss()(logits, labels)
    tv_loss = tversky_loss(logits, labels, alpha=alpha, beta=beta, smooth=smooth)
    return weight_ce * ce_loss + weight_tv * tv_loss

def compute_pixel_accuracy(preds, labels):
    preds = preds.flatten()
    labels = labels.flatten()
    correct_pixels = (preds == labels).sum().item()
    total_pixels = labels.numel()
    return correct_pixels / total_pixels

def compute_dice_coefficient(preds, labels, num_classes=2):
    dice_scores = []
    for i in range(num_classes):
        intersection = torch.sum((preds == i) & (labels == i))
        total_pixels = torch.sum((preds == i) + (labels == i))
        dice = (2 * intersection.float()) / (total_pixels.float() + 1e-10)
        dice_scores.append(dice.item())
    return sum(dice_scores) / len(dice_scores)

def compute_iou(preds, labels, num_classes):
    preds = preds.flatten()
    labels = labels.flatten()
    iou_list = []
    for i in range(num_classes):
        intersection = torch.sum((preds == i) & (labels == i))
        union = torch.sum((preds == i) | (labels == i))
        iou = intersection.float() / (union.float() + 1e-10)
        iou_list.append(iou.item())
    return sum(iou_list) / len(iou_list)

# === PyTorch Lightning Module ===
class LitSegformer(pl.LightningModule):
    def __init__(self, num_labels=NUM_CLASSES, learning_rate=5e-5, weight_decay=0.01):
        super().__init__()
        self.save_hyperparameters()
        # Using the B0 checkpoint as a better baseline
        self.model = SegformerForSemanticSegmentation.from_pretrained(
            "nvidia/segformer-b0-finetuned-ade-512-512",
            num_labels=num_labels,
            ignore_mismatched_sizes=True
        )
    
    def forward(self, pixel_values):
        return self.model(pixel_values=pixel_values)
    
    def training_step(self, batch, batch_idx):
        labels = batch["labels"]
        pixel_values = batch["pixel_values"]
        outputs = self.model(pixel_values=pixel_values)
        logits = outputs.logits
        loss = combined_loss(logits, labels)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def validation_step(self, batch, batch_idx):
        labels = batch["labels"]
        pixel_values = batch["pixel_values"]
        outputs = self.model(pixel_values=pixel_values)
        logits = outputs.logits
        loss = combined_loss(logits, labels)
        preds = torch.argmax(logits, dim=1)
        acc = compute_pixel_accuracy(preds, labels)
        dice = compute_dice_coefficient(preds, labels, num_classes=NUM_CLASSES)
        iou = compute_iou(preds, labels, num_classes=NUM_CLASSES)
        self.log("val_loss", loss, prog_bar=True)
        self.log("val_acc", acc, prog_bar=True)
        self.log("val_dice", dice, prog_bar=True)
        self.log("val_iou", iou, prog_bar=True)
        return {"val_loss": loss, "val_acc": acc, "val_dice": dice, "val_iou": iou}

    def configure_optimizers(self):
        optimizer = torch.optim.AdamW(
            self.parameters(), 
            lr=self.hparams.learning_rate, 
            weight_decay=self.hparams.weight_decay
        )
        return optimizer

# === Data Setup ===
if __name__ == "__main__":
    # Use the B0-compatible processor
    feature_extractor = SegformerImageProcessor.from_pretrained("nvidia/segformer-b0-finetuned-ade-512-512")
    train_dataset = SegmentationDataset(IMAGE_DIR, MASK_DIR, feature_extractor)
    val_dataset = SegmentationDataset(TEST_IMAGE_DIR, TEST_MASK_DIR, feature_extractor)
    
    train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)
    val_dataloader = DataLoader(val_dataset, batch_size=4)
    
    # Initialize the Lightning module and trainer
    model = LitSegformer(num_labels=NUM_CLASSES)
    trainer = pl.Trainer(
        max_epochs=1,
        gpus=1 if torch.cuda.is_available() else 0,
        log_every_n_steps=10
    )
    
    # Start training
    trainer.fit(model, train_dataloader, val_dataloader)
